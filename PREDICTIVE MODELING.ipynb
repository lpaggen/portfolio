{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEO JEAN (LJ) PAGGEN\n",
    "\n",
    "i6236337"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "\n",
    "# Clinic 2: Regress the price!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DELIVERABLES (DEADLINE 10/March late night, wildcards possible)\n",
    "\n",
    "Instructions for the deliverable: \n",
    "\n",
    "* Make sure that you include a proper amount/mix of comments, results and code.\n",
    "\n",
    "* In the end, make sure that all cells are executed properly and everything you need to show is in your (execucted) notebook.\n",
    "\n",
    "* You are asked to deliver **only your executed notebook file, .ipnyb** and nothing else. Enjoy!\n",
    "\n",
    "* The second part of the assignment is purposefully left open-ended.  You will be allowed to build a linear model of your choice to better predict the price. \n",
    "\n",
    "* Honor code applies to these tasks. Only individual work should be submitted.\n",
    "\n",
    "* Data science is a collaborative activity. While you may talk with others about the clinic, we ask that you **write your solutions individually**. If you do discuss the assignments with others please **include their names** below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Names of collaborators**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Introduction\n",
    "\n",
    "In this clinic, we will go through the iterative process of specifying, fitting, and refining a model.  \n",
    "\n",
    "In the first part of the assignment, we will guide you through some basic EDA, laying out the thought process that leads to certain modeling decisions.  We will then specify and fit more linear models, providing an example of the type of code we expect from you in the open-response.\n",
    "\n",
    "The second part of the assignment is purposefully left open-ended.  You will be allowed to build a linear model of your choice to better predict the price. \n",
    "\n",
    "After this homework, you should feel comfortable with the following:\n",
    "\n",
    "1. Working with a messy data set that requires a moderate amount of cleaning and wrangling\n",
    "1. Using `sklearn` to build models\n",
    "1. Using several different transformations on your data\n",
    "1. Building a data pipeline using pandas\n",
    "1. Using cross-validation for model selection\n",
    "\n",
    "## Score breakdown\n",
    "\n",
    "Question | Points\n",
    "--- | ---\n",
    "[Question 1a](#q1a) | 2\n",
    "[Question 1b](#q1b) | 3\n",
    "[Question 2](#q2) | 5\n",
    "[Question 3](#q3) | 25\n",
    "[Question 4](#q4) | 5\n",
    "[Question 5](#q5) | 5\n",
    "[Question 6](#q6) | 5\n",
    "Total | 50\n",
    "\n",
    "This score will be scaled down to 1 and that will be your final clinic score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessary imports (edit as you see fit)\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Plot settings\n",
    "plt.rcParams['figure.figsize'] = (12, 9)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 The Data\n",
    "\n",
    "The datset consists of 2930 records for house prices. The data are real and stem from the Ames Assessor's Office. They were used in computing assessed values for individual residential properties sold in Ames, IA from 2006 to 2010. The data set has 23 nominal, 23 ordinal, 14 discrete, and 20 continuous variables (and 2 additional observation identifiers) --- 82 features in total.  An explanation of each variable can be found in the included `codebook.txt` file. **Some noise has been added to the actual sale price, so prices will not match official records or other versions of the dataset to be found online, so please don't try to cheat!**\n",
    "\n",
    "The data are split into training and test sets with 2000 and 930 observations, respectively.  The test set provided here is for you to build your models. \n",
    "\n",
    "### 0.1.1 A little bit on the background on these house pricing datasets\n",
    "In the United States, all property owners are required to pay property taxes, which are then used to fund public services including education, road maintenance, and sanitation. These property tax assessments are based on property values estimated using statistical models that consider multiple factors, such as real estate value and construction cost.\n",
    "\n",
    "This system, however, is not without flaws. In late 2017, a lawsuit was filed against the office of Cook County Assessor Joseph Berrios for producing [“racially discriminatory assessments and taxes.\"](https://www.chicagotribune.com/politics/ct-cook-county-board-assessor-berrios-met-20170718-story.html) The lawsuit included claims that the assessor’s office undervalued high-priced homes and overvalued low-priced homes, creating a visible divide along racial lines: Wealthy homeowners, who were typically white, [paid less in property taxes](https://www.clccrul.org/bpnc-v-berrios-facts?rq=berrios), whereas [working-class, non-white homeowners paid more](https://www.chicagotribune.com/news/breaking/ct-cook-county-assessor-berrios-sued-met-20171214-story.html).\n",
    "\n",
    "The Chicago Tribune's four-part series, [\"The Tax Divide\"](https://www.chicagotribune.com/investigations/ct-tax-divide-investigation-20180425-storygallery.html), delves into how this was uncovered: After \"compiling and analyzing more than 100 million property tax records from the years 2003 through 2015, along with thousands of pages of documents, then vetting the findings with top experts in the field,\" they discovered that \"residential assessments [had] been so far off the mark for so many years.\" You can read more about their investigation [here](https://apps.chicagotribune.com/news/watchdog/cook-county-property-tax-divide/assessments.html).\n",
    "\n",
    "Additionally, the discrimination described in the lawsuit is built on a much deeper history - including the practice of redlining in Chicago. Though this is by no means a comprehensive history, Merriam-Webster defines redlining as the \"withholdding of home-loan funds or insurance from neighborhoods considered poor economic risks.\" The neighborhoods in this category, however, were typically comprised of Black communities; redlining, then, systemically prevented Black residents from moving into other neighborhoods and improving their current homes by denying them the financial assistance that white residents were afforded. Though the Fair Housing Act of 1968 outlawed redlining, its [impacts](https://www.washingtonpost.com/news/wonk/wp/2018/03/28/redlining-was-banned-50-years-ago-its-still-hurting-minorities-today/) and [practices](https://www.chicagotribune.com/business/ct-biz-modern-day-redlining-20180215-story.html) are still present today.\n",
    "\n",
    "This context is vital to understanding how different datasets might be created. This introduction aims to address how legacies of racial discrimination practices can be encoded within data, as well as consider how they might influence modeling choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(\"ames_train.csv\")\n",
    "test_data = pd.read_csv(\"ames_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "528d80c0381c45f44c1734ba04056d63",
     "grade": false,
     "grade_id": "cell-9d6d509b6e854e10",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "As a good sanity check, we should at least verify that the data shape matches the description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1977 observations and 82 features in training data\n",
    "assert training_data.shape == (1977, 82)\n",
    "# 799 observations and 82 features in test data\n",
    "assert test_data.shape == (799, 82)\n",
    "# Every column in the test data should be in the training data\n",
    "assert len(np.intersect1d(test_data.columns.values, \n",
    "                          training_data.columns.values)) == 82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e7e804b381f5c3ba5ea29b2df70bc92c",
     "grade": false,
     "grade_id": "cell-ce9acc2f62c96e59",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "The next order of business is getting a feel for the variables in our data.  The Ames data set contains information that typical homebuyers would want to know.  A more detailed description of each variable is included in `codebook.txt`.  **You should take some time to familiarize yourself with the codebook before moving forward.** If you find any issues or inconsistencies in the codebook, please report them to us!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f542e637735a9ff2be37b5e2f2ea35b1",
     "grade": false,
     "grade_id": "cell-4e60a7a0cda5eecf",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "training_data.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Guided Modeling\n",
    "\n",
    "In the first part of the assignment, we will take you step-by-step through one cycle of the modeling process.  Along the way, we will provide commentary to give you a sense of the thought process that goes into building a model. We give examples on most of the common cases we have explored (EDA, missing values, feature engineering etc.), but feel free to extend this analyses for your final model.\n",
    "\n",
    "## 1.1 EDA\n",
    "Naturally, the first thing we want to do is get a feel for our data.  In this section, we will make a series of exploratory visualizations.  The plots we ask you to reproduce here are far from exhaustive. **When you build your own model in the second part of this assignment, you will want to delve deeper into the data.**\n",
    "\n",
    "Note that we will perform EDA on the **training data** so that information from the test data does not influence our modeling decisions.\n",
    "\n",
    "### 1.1.1 Sale Price\n",
    "We begin by examining a [raincloud plot](https://www.kaggle.com/code/carlmcbrideellis/box-strip-violin-raincloud-plot) (yet another name for a combination of a KDE, a boxplot, and a boxplot all-in-one) of our target variable `SalePrice`.  At the same time, we also take a look at some descriptive statistics of this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2)\n",
    "\n",
    "sns.histplot(\n",
    "    training_data['SalePrice'],\n",
    "    kde=True,\n",
    "    ax=axs[0]\n",
    ")\n",
    "\n",
    "sns.stripplot(\n",
    "    training_data['SalePrice'], \n",
    "    orient='h',\n",
    "    jitter=0.4, \n",
    "    size=3,\n",
    "    ax=axs[1],\n",
    "    alpha=0.3\n",
    ")\n",
    "sns.boxplot(\n",
    "    training_data['SalePrice'],\n",
    "    orient='h',\n",
    "    width=0.4, \n",
    "    ax=axs[1],\n",
    "    showfliers=False,\n",
    ")\n",
    "\n",
    "# Align axes\n",
    "spacer = np.max(training_data['SalePrice']) * 0.05\n",
    "xmin = np.min(training_data['SalePrice']) - spacer\n",
    "xmax = np.max(training_data['SalePrice']) + spacer\n",
    "axs[0].set_xlim((xmin, xmax))\n",
    "axs[1].set_xlim((xmin, xmax))\n",
    "\n",
    "# Remove some axis text\n",
    "axs[0].xaxis.set_visible(False)\n",
    "axs[0].yaxis.set_visible(False)\n",
    "axs[1].yaxis.set_visible(False)\n",
    "\n",
    "# Put the two plots together\n",
    "plt.subplots_adjust(hspace=0)\n",
    "\n",
    "# Adjust boxplot fill to be white\n",
    "axs[1].set_facecolor('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary statistics for price\n",
    "training_data['SalePrice'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check your understanding of the graph and summary statistics above, answer the following `True` or `False` questions:\n",
    "\n",
    "1. The distribution of `SalePrice` in the training set is left-skew.\n",
    "1. The mean of `SalePrice` in the training set is greater than the median.\n",
    "1. 75% of the houses in the training set sold for less than \\$214,000.00.\n",
    "\n",
    "If you have trouble answering the questions above, discuss them in class with each other and confirm with a TA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 SalePrice vs Gr_Liv_Area\n",
    "\n",
    "Next, we examine `SalePrice` vs `Gr_Liv_Area`.  Now it's not entirely obvious what `Gr_Liv_Area` should be, so we'll need to consult `codebook.txt`.  We find:\n",
    "\n",
    "```\n",
    "Gr Liv Area (Continuous): Above grade (ground) living area square feet\n",
    "```\n",
    "\n",
    "Ok, so this variable represents the square footage of the house excluding anything built underground.  Some additional research (into real estate conventions) reveals that this value also excludes the garage space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(\n",
    "    x='Gr_Liv_Area',\n",
    "    y='SalePrice',\n",
    "    data=training_data,\n",
    "#    stat_func=None,\n",
    "    kind=\"reg\",\n",
    "    ratio=4,\n",
    "    space=0,\n",
    "    scatter_kws={\n",
    "        's': 3,\n",
    "        'alpha': 0.25\n",
    "    },\n",
    "    line_kws={\n",
    "        'color': 'black'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that there is a plausible linear relationship between house size and sale price, but the spread is wider at larger sale prices and above grade living areas.  There seem to be two particularly suspicious houses above 5000 square feet.\n",
    "\n",
    "What do we do when we have outliers? Let's check them properly!\n",
    "\n",
    "What are the Parcel Indentification Numbers for the two houses with `Gr_Liv_Area` greater than 5000 sqft? That's something that can be answered just through Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: You can answer this question purely through pandas\n",
    "# q2house1 and q2house2 should be integers\n",
    "q2house1 = training_data[\"PID\"][training_data[\"Gr_Liv_Area\"] > 5000].iloc[0].item()\n",
    "q2house2 = training_data[\"PID\"][training_data[\"Gr_Liv_Area\"] > 5000].iloc[1].item()\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None) \n",
    "q2house1,q2house2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The codebook actually tells us how to manually inspect the houses using an online database called Beacon. These two houses are true outliers in this data set.  They were partial sales that were priced much under market value.  We will remove them in the guided model, but perhaps you will want to address them differently in your own model.  To make sure you know how to view the online database, please answer the following question:\n",
    "\n",
    "What are the gross values of the two houses with `Gr_Liv_Area` greater than 5000 as of 2022?  You will find this under the section titled \"Valuation (Ames)\".  Your answers should be integers.\n",
    "\n",
    "A note to use the Beacon database: You can use the PID as in the data, but you need to prefix 0. So, if the PID of a house is 999235239, you can find it in the database as 0999235239."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q3house1 = 2,310,300\n",
    "q3house2 = 1,747,900"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we write a function `remove_outliers` that removes outliers from a data set based off a threshold value of a variable. For example, `remove_outliers(training_data, 'Gr_Liv_Area', upper=5000)` should return a data frame with only observations that satisfy `Gr_Liv_Area` less than or equal to 5000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(data, variable, lower=-np.inf, upper=np.inf):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      data (data frame): the table to be filtered\n",
    "      variable (string): the column with numerical outliers\n",
    "      lower (numeric): observations with values lower than this will be removed\n",
    "      upper (numeric): observations with values higher than this will be removed\n",
    "    \n",
    "    Output:\n",
    "      a winsorized data frame with outliers removed\n",
    "    \"\"\"\n",
    "    return data.loc[(data[variable] > lower) & (data[variable] < upper)]\n",
    "\n",
    "\n",
    "training_data = remove_outliers(training_data, 'Gr_Liv_Area', upper=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making sure the two observations were removed\n",
    "assert training_data.shape[0] == 1975"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 Neighborhood vs Sale Price\n",
    "\n",
    "Next we explore this relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2)\n",
    "\n",
    "sns.boxplot(\n",
    "    x='Neighborhood',\n",
    "    y='SalePrice',\n",
    "    data=training_data.sort_values('Neighborhood'),\n",
    "    ax=axs[0]\n",
    ")\n",
    "\n",
    "sns.countplot(\n",
    "    x='Neighborhood',\n",
    "    data=training_data.sort_values('Neighborhood'),\n",
    "    ax=axs[1]\n",
    ")\n",
    "\n",
    "# Draw median price\n",
    "axs[0].axhline(\n",
    "    y=training_data['SalePrice'].median(), \n",
    "    color='red',\n",
    "    linestyle='dotted'\n",
    ")\n",
    "\n",
    "# Label the bars with counts\n",
    "for patch in axs[1].patches:\n",
    "    x = patch.get_bbox().get_points()[:, 0]\n",
    "    y = patch.get_bbox().get_points()[1, 1]\n",
    "    axs[1].annotate(f'{int(y)}', (x.mean(), y), ha='center', va='bottom')\n",
    "    \n",
    "# Format x-axes\n",
    "axs[1].set_xticklabels(axs[1].xaxis.get_majorticklabels(), rotation=90)\n",
    "axs[0].xaxis.set_visible(False)\n",
    "\n",
    "# Narrow the gap between the plots\n",
    "plt.subplots_adjust(hspace=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot above, it becomes clear that there is quite some variation in prices across neighborhoods.  Moreover, the amount of data available is not uniformly distributed among neighborhoods.  North Ames, for example, comprises almost 15% of the training data while Green Hill has a scant 2 observations in this data set.\n",
    "\n",
    "One way we can deal with the lack of data from some neighborhoods is to create a new feature that bins neighborhoods together.  Let's dichotomize our neighborhoods in a very crude way: we'll take the top 3 neighborhoods measured by median `SalePrice` and identify them as \"rich neighborhoods\"; the other neighborhoods are not marked.\n",
    "\n",
    "Now we write a function that returns list of the top-$n$ most pricey neighborhoods as measured by our choice of aggregating function.  For example, in the setup above, we would want to call `find_rich_neighborhoods(training_data, 3)` to find the top 3 neighborhoods measured by median `SalePrice`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def find_rich_neighborhoods(data, n=3):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      data (data frame): should contain at least a string-valued Neighborhood\n",
    "        and a numeric SalePrice column\n",
    "      n (int): the number of top values desired\n",
    "    \n",
    "    Output:\n",
    "      a list of the top n richest neighborhoods as measured by the metric function\n",
    "    \"\"\"\n",
    "    neighborhoods = data.groupby(\"Neighborhood\")[\"SalePrice\"].median().sort_values(ascending=False).iloc[:n].index.values.tolist()\n",
    "    #deprecated -->\n",
    "    #neighborhoods = data.groupby(\"Neighborhood\").agg(metric).sort_values(by=[\"SalePrice\"],ascending=False).iloc[:n].index.values.tolist()\n",
    "    return neighborhoods\n",
    "\n",
    "rich_neighborhoods = find_rich_neighborhoods(training_data, 3)\n",
    "rich_neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if the n argument works\n",
    "assert len(find_rich_neighborhoods(training_data, 5)) == 5\n",
    "assert isinstance(rich_neighborhoods, list)\n",
    "# Check to see if the list contains only strings\n",
    "assert all([isinstance(neighborhood, str) for neighborhood in rich_neighborhoods])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Missing Data\n",
    "\n",
    "Let's see if our data set has any missing values.  Create a Series object containing the counts of missing values in each of the columns of our data set sorted from greatest to least.  The Series should be indexed by the variable names. For example, `missing_counts['Fireplace_Qu']` should return 959."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_counts = len(training_data.index) - training_data.count()\n",
    "\n",
    "missing_counts['Fireplace_Qu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure your answer is a Series\n",
    "assert isinstance(missing_counts, pd.Series)\n",
    "# Make sure all columns are represented\n",
    "assert missing_counts.size == 82\n",
    "# Make sure your index values match column names\n",
    "assert set(missing_counts.index.values) == set(training_data.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that if we look at the codebook carefully, some of these \"missing values\" aren't missing at all! The Assessor's Office just used `NA` to denote a special value or that the information was truly not applicable for one reason or another.  One such example is the `Fireplace_Qu` variable.\n",
    "```\n",
    "FireplaceQu (Ordinal): Fireplace quality\n",
    "\n",
    "       Ex\tExcellent - Exceptional Masonry Fireplace\n",
    "       Gd\tGood - Masonry Fireplace in main level\n",
    "       TA\tAverage - Prefabricated Fireplace in main living area or Masonry Fireplace inbasement\n",
    "       Fa\tFair - Prefabricated Fireplace in basement\n",
    "       Po\tPoor - Ben Franklin Stove\n",
    "       NA\tNo Fireplace\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An `NA` here actually means that the house had no fireplace to rate.  Let's fix this in our data set.  Write a function that replaces the missing values in `Fireplace_Qu` with `'No Fireplace'`.  In addition, it should replace each abbreviated condition with its full word.  For example, `'TA'` should be changed to `'Average'`.  Hint: the [DataFrame.replace](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.replace.html) method may be useful here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_fireplace_qu(data):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      data (data frame): a data frame containing a Fireplace_Qu column.  Its values\n",
    "                         should be limited to those found in the codebook\n",
    "    Output:\n",
    "      data frame identical to the input except with a refactored Fireplace_Qu column\n",
    "    \"\"\"\n",
    "    dictz = {\n",
    "        \"Ex\":\"Excellent\",\n",
    "        \"Gd\":\"Good\",\n",
    "        \"TA\":\"Average\",\n",
    "        \"Fa\": \"Fair\",\n",
    "        \"Po\": \"Poor\",\n",
    "    }\n",
    "    data['Fireplace_Qu'] = data['Fireplace_Qu'].replace(dictz)\n",
    "    data['Fireplace_Qu'] = data['Fireplace_Qu'].fillna(value=\"No Fireplace\")\n",
    "    return data\n",
    "\n",
    "training_data = fix_fireplace_qu(training_data)\n",
    "\n",
    "training_data['Fireplace_Qu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you've replaced all the missing values with 'No Fireplace'\n",
    "assert sum(training_data['Fireplace_Qu'] == 'No Fireplace') == 959"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that simply fixing these missing values isn't sufficient for using `Fireplace_Qu` in our model.  Since `Fireplace_Qu` is a categorical/nominal variable, we will have to one-hot-encode the data.  Notice in the example code below that we have to pre-specify the categories.  Why? Imagine what would happen if we automatically generated the categories only from the training data.  What would happen if the testing data contained a category not found in the training set?  For more information on categorical data in pandas, refer to this [link](https://pandas-docs.github.io/pandas-docs-travis/categorical.html).  **Note that `get_dummies` removes the original column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ohe_fireplace_qu(data):\n",
    "    \"\"\"\n",
    "    One-hot-encodes fireplace quality.  New columns are of the form fpq_QUALITY\n",
    "    \"\"\"\n",
    "    cats = [\n",
    "        'Excellent',\n",
    "        'Good',\n",
    "        'Average',\n",
    "        'Fair',\n",
    "        'Poor',\n",
    "        'No Fireplace'\n",
    "    ]\n",
    "\n",
    "    cat_type = CategoricalDtype(categories=cats)\n",
    "\n",
    "    data['Fireplace_Qu'] = data['Fireplace_Qu'].astype(cat_type)\n",
    "    data = pd.get_dummies(data,\n",
    "                          prefix='fpq',\n",
    "                          columns=['Fireplace_Qu'],\n",
    "                          drop_first=True)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = ohe_fireplace_qu(training_data)\n",
    "training_data.filter(regex='fpq').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Feature Engineering\n",
    "\n",
    "In this section we will create a new feature out of existing ones through a simple data transformation.  When you move on to create your own model, you may want to try out more complex transformations.\n",
    "\n",
    "### 1.3.1 Bathrooms\n",
    "\n",
    "We will create a groundbreaking new feature. Due to recent advances in Universal WC Enumeration Theory, we now know that Total Bathrooms can be calculated as:\n",
    "\n",
    "$$ TotalBathrooms=(BsmtFullBath + FullBath) + \\dfrac{1}{2}(BsmtHalfBath + HalfBath)$$\n",
    "\n",
    "The actual proof is beyond the scope of this class, but we will use the result in our model.\n",
    "\n",
    "We write a function `add_total_bathrooms(data)` that returns the input data frame with a new column called `total_bathrooms` as calculated above. Note that we Treat missing values as 0s and we make extensive use of vectorized code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_total_bathrooms(data):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      data (data frame): a data frame containing at least 4 numeric columns \n",
    "            Bsmt_Full_Bath, Full_Bath, Bsmt_Half_Bath, and Half_Bath\n",
    "    Output:\n",
    "      data frame identical to the input with the addition of a total_bathrooms column\n",
    "    \"\"\"\n",
    "    a = data.loc[:,\"Bsmt_Full_Bath\"].fillna(value=0)\n",
    "    b = data.loc[:,\"Full_Bath\"].fillna(value=0)\n",
    "    c = 0.5*data.loc[:,\"Bsmt_Half_Bath\"].fillna(value=0)\n",
    "    d = 0.5*data.loc[:,\"Half_Bath\"].fillna(value=0)\n",
    "    data[\"total_bathrooms\"] = a+b+c+d\n",
    "    return data\n",
    "\n",
    "training_data = add_total_bathrooms(training_data)\n",
    "\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that missing values are dealt with\n",
    "assert ~training_data['total_bathrooms'].isnull().any()\n",
    "# Check that the values are as expected\n",
    "assert training_data['total_bathrooms'].sum() == 4367.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Rich Neighborhoods\n",
    "\n",
    "From before, we have a list of neighborhoods we've deemed as richer than others.  Let's use that information to make a new variable `in_rich_neighborhood`. We write a function `add_rich_neighborhood` that adds an indicator variable which takes on the value 1 if the house is part of `rich_neighborhoods` and the value 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_in_rich_neighborhood(data, neighborhoods):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "      data (data frame): a data frame containing a 'Neighborhood' column with values\n",
    "        found in the codebook\n",
    "      neighborhoods (list of strings): strings should be the names of neighborhoods\n",
    "        pre-identified as rich\n",
    "    Output:\n",
    "      data frame identical to the input with the addition of a binary\n",
    "      in_rich_neighborhood column\n",
    "    \"\"\"\n",
    "    data[\"in_rich_neighborhood\"] = 0\n",
    "    mask = data[\"Neighborhood\"].isin(neighborhoods)\n",
    "    data.loc[mask,\"in_rich_neighborhood\"] = 1\n",
    "    return data\n",
    "\n",
    "rich_neighborhoods = find_rich_neighborhoods(training_data, 3)\n",
    "training_data = add_in_rich_neighborhood(training_data, rich_neighborhoods)\n",
    "\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if you have identified the correct number of rich neighborhoods\n",
    "assert sum(training_data['in_rich_neighborhood']) == 191\n",
    "# Check to see if you've introduced any missing values\n",
    "assert sum(training_data['in_rich_neighborhood'].isnull()) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Modeling\n",
    "\n",
    "We've finally gotten to a point where we can specify a simple model.  But first, we need to create perform a test-train split of our data.  We begin by loading a fresh copy of the data in at this point just in case our code above produced any undesired side-effects.  At this point, we will begin to treat `ames_train.csv` as our complete data set.  We will use `train_test_split` from `sklearn` to split the data into `test` and `train` sets.\n",
    "\n",
    "Remember: The reason we have to do a train-test split on `ames_train.csv` here is because we want to evaluate how well our model might perform on future data (`ames_test.csv`), but that data set does not have `SalePrice` in it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a fresh copy of the data\n",
    "full_data = pd.read_csv(\"ames_train.csv\")\n",
    "\n",
    "# This makes the train-test split in this section reproducible across different runs \n",
    "# of the notebook.  You do not need this line to run train_test_split in general\n",
    "np.random.seed(1337) \n",
    "\n",
    "# Split the data \n",
    "train, test = train_test_split(full_data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Something has gone awry in the cell above if these do not pass\n",
    "assert test.shape == (396, 82)\n",
    "assert train.shape == (1581, 82)\n",
    "assert train.loc[887, 'PID'] == 902402260"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Reusable Pipeline\n",
    "\n",
    "Throughout this assignment, you should notice that your data flows through a single processing pipeline several times.  From a software engineering perspective, this should be sufficient motivation to abstract parts of our code into reusable functions/methods.  We will now encapsulate our entire pipeline into a single function `process_data_gm`.  gm is shorthand for \"guided model\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns(data, *columns):\n",
    "    return data.reindex(columns = columns)\n",
    "    #deprecated:\n",
    "    #return data.loc[:, columns]\n",
    "\n",
    "def process_data_gm1(data):\n",
    "    # Clean Data\n",
    "    data = remove_outliers(data, 'Gr_Liv_Area', upper=5000)\n",
    "    data = fix_fireplace_qu(data)\n",
    "\n",
    "    # Transform Data\n",
    "    data = add_total_bathrooms(data)\n",
    "    data = add_in_rich_neighborhood(data, rich_neighborhoods)\n",
    "    data = select_columns(data, \n",
    "                          'SalePrice', \n",
    "                          'Gr_Liv_Area', \n",
    "                          'total_bathrooms',\n",
    "                          'Fireplace_Qu',\n",
    "                          'in_rich_neighborhood'\n",
    "                         )\n",
    "    data = ohe_fireplace_qu(data)\n",
    "\n",
    "    # Return predictors and response variables separately\n",
    "    X = data.drop(['SalePrice'], axis = 1)\n",
    "    y = data['SalePrice']\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative way of writing the same code above explicitly allows us to think about our data flowing through a [pipeline](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.pipe.html) where the output of one function is the input of the next.  Carefully thought out function names make the code self-documenting: you can just read off the intended high-level processing steps from top to bottom.\n",
    "\n",
    "You are not required to use this style of coding.  We just wanted to point out that it exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_gm1(data):\n",
    "\n",
    "    data = (\n",
    "        data\n",
    "        # Clean Data\n",
    "        .pipe(remove_outliers, 'Gr_Liv_Area', upper=5000)\n",
    "        .pipe(fix_fireplace_qu)\n",
    "        \n",
    "        # Transform data\n",
    "        .pipe(add_total_bathrooms)\n",
    "        .pipe(add_in_rich_neighborhood, rich_neighborhoods)\n",
    "        .pipe(select_columns, \n",
    "              'SalePrice',           \n",
    "              'Gr_Liv_Area',            \n",
    "              'total_bathrooms',             \n",
    "              'Fireplace_Qu',            \n",
    "              'in_rich_neighborhood'\n",
    "             )\n",
    "        .pipe(ohe_fireplace_qu)\n",
    "    ) \n",
    "    \n",
    "    # Return predictors and response variables separately\n",
    "    X = data.drop(['SalePrice'], axis = 1)\n",
    "    y = data['SalePrice']\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Fitting our first model\n",
    "\n",
    "We are finally going to fit a model (yay!). This part is slightly unceremonious since we did much of the heavy lifting in the previous sections.  The model we will fit can be written as follows (with the caveat that one of the fireplace qualities is actually removed to avoid collinearity):\n",
    "\n",
    "$$\\begin{align} SalePrice = &\\theta_0 + \\theta_1 \\times GrLivArea + \\theta_2 \\times TotalBathrooms \\\\\n",
    "&+ \\theta_3 \\times InRichNeighborhood + \\sum_{quality \\in FireplaceQuality} \\theta_{quality} \\times Quality\n",
    "\\end{align}$$\n",
    "\n",
    "#### Question 1a <a name=\"q1a\"></a>\n",
    "Remove the commenting and fill in the ellipses `...` below with `X_train`, `y_train`, `X_test`, or `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = process_data_gm1(train)\n",
    "X_test, y_test = process_data_gm1(test)\n",
    "guidedmodel1 = lm.LinearRegression(fit_intercept=True)\n",
    "\n",
    "guidedmodel1.fit(X_train, y_train)\n",
    "y_fitted = guidedmodel1.predict(X_train)\n",
    "y_predicted = guidedmodel1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_fitted.mean())\n",
    "print(y_predicted.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 181100 <= y_fitted.mean() <= 183400\n",
    "assert 177600 <= y_predicted.mean() <= 177900"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will use Root-Mean-Square Error (RMSE) to measure the quality of our models.  As a reminder, this quantity is defined as:\n",
    "\n",
    "$RMSE = \\sqrt{\\dfrac{\\sum_{\\text{houses in test set}}(\\text{actual price of house} - \\text{predicted price of house})^2}{\\text{# of houses in test set}}}$\n",
    "\n",
    "#### Question 1b <a name=\"q1b\"></a>\n",
    "\n",
    "Write a function `rmse` that calculates the RMSE of a model.  Again, make sure you are taking advantage of vectorized code.  This can be solved without any iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(actual, predicted):\n",
    "    \"\"\"\n",
    "    Calculates RMSE from actual and predicted values\n",
    "    Input:\n",
    "      actual (1D array-like): vector of actual values\n",
    "      predicted (1D array-like): vector of predicted/fitted values\n",
    "    Output:\n",
    "      a float, the root-mean square error\n",
    "    \"\"\"\n",
    "\n",
    "    rmse = np.sqrt(np.mean((np.array(actual) - np.array(predicted)) ** 2))\n",
    "\n",
    "    return rmse\n",
    "\n",
    "rmse(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 44000 <= rmse(y_test, y_predicted) <= 46000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Checking our model: Residual Plots\n",
    "\n",
    "Recall from the lectures, that one way of diagnosing a model is through a residual plot.  Here we plot the actual sale prices against the residuals of the model.  Ideally, we would see a horizontal line of points at 0 (perfect prediction!).  The next best thing would be a homogenous set of points centered at 0.  But alas, our simple model is probably too simple.  We notice that we are really underfitting the more expensive homes in the test set.  In fact, it looks like our model tends to underprice the more expensive homes!  You will probably want to address this in your own work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm1_residuals = y_test - y_predicted\n",
    "ax = sns.regplot(x=y_test, y=gm1_residuals)\n",
    "ax.set_xlabel('Sale Price (Test Data)')\n",
    "ax.set_ylabel('Residuals (Actual Price - Predicted Price)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Regularizing our model\n",
    "\n",
    "Ok, so let's make our modeling a little more fancy by regularizing the coefficients.  This second model will use the Lasso, but you are free to use Ridge or other in your work.  First, we need to add a step to our pre-processing.  In order for regularization to be fair to all the variables in our model, we need to standardize our predictor columns (otherwise it would unfairly penalize variables with inherently small values).\n",
    "\n",
    "#### Question 2 <a name=\"q2\"></a>\n",
    "\n",
    "Write a function that standardizes the columns of a data frame containing only numeric columns.  Be sure to make use of vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_columns(data):\n",
    "    '''\n",
    "    Input:\n",
    "      data (data frame): contains only numeric columns\n",
    "    Output:\n",
    "      data frame, the same data, except each column is standardized \n",
    "      to have 0-mean and unit variance\n",
    "    '''\n",
    "    standardized_data = (data - np.mean(data)) / np.std(data) # z score\n",
    "\n",
    "    return standardized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_standardize_df = standardize_columns(training_data[['SalePrice', 'Gr_Liv_Area']])\n",
    "# Make sure the mean is correct\n",
    "assert -0.001 < test_standardize_df.mean().sum() < 0.001\n",
    "# Make sure the standard deviation is correct\n",
    "assert 1.9 < test_standardize_df.std().sum() < 2.1\n",
    "\n",
    "test_standardize_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now use this function to describe our new processing for the regularized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_gm2(data):\n",
    "\n",
    "    data = (\n",
    "        data\n",
    "        # Clean Data\n",
    "        .pipe(remove_outliers, 'Gr_Liv_Area', upper=5000)\n",
    "        .pipe(fix_fireplace_qu)\n",
    "\n",
    "        # Transform data\n",
    "        .pipe(add_total_bathrooms)\n",
    "        .pipe(add_in_rich_neighborhood, rich_neighborhoods)\n",
    "        .pipe(select_columns, \n",
    "              'SalePrice',           \n",
    "              'Gr_Liv_Area',            \n",
    "              'total_bathrooms',             \n",
    "              'Fireplace_Qu',            \n",
    "              'in_rich_neighborhood'\n",
    "             )\n",
    "        .pipe(ohe_fireplace_qu)\n",
    "    )\n",
    "\n",
    "    # Return predictor and response variables separately\n",
    "    X = standardize_columns(data).drop(['SalePrice'], axis = 1)\n",
    "    y = data['SalePrice']\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may be instructive to see the cross-validation procedure explicitly once.  You should be able to understand what each part of the code is doing below, but we do not expect you to use this code for your own model (use [LassoCV](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html) instead)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process our data\n",
    "X_train, y_train = process_data_gm2(train)\n",
    "X_test, y_test = process_data_gm2(test)\n",
    "\n",
    "# Specify our model\n",
    "guidedmodel2 = lm.Lasso(copy_X=True)\n",
    "\n",
    "# Specify CV method and alpha grid\n",
    "five_fold_cv = KFold(n_splits = 5)\n",
    "alphas = np.arange(0.1, 200.1, .1)\n",
    "rmses = np.zeros(len(alphas))\n",
    "\n",
    "# Grid search over alphas\n",
    "for i, alpha in enumerate(alphas):\n",
    "    guidedmodel2.set_params(alpha=alpha)\n",
    "    model_rmse = 0\n",
    "    \n",
    "    # Fit each fold using the other four as training data\n",
    "    for train_index, test_index in five_fold_cv.split(X_train):\n",
    "        X_fold_train = X_train.iloc[train_index]\n",
    "        y_fold_train = y_train.iloc[train_index]\n",
    "        X_fold_test = X_train.iloc[test_index]\n",
    "        y_fold_test = y_train.iloc[test_index]\n",
    "        \n",
    "        guidedmodel2.fit(X_fold_train, y_fold_train)\n",
    "        y_fold_predicted = guidedmodel2.predict(X_fold_test)\n",
    "        model_rmse += rmse(y_fold_test, y_fold_predicted)\n",
    "    \n",
    "    # Average RMSE over the five folds for alpha_i\n",
    "    rmses[i] = model_rmse / 5\n",
    "\n",
    "optimal_alpha = alphas[rmses == np.min(rmses)]\n",
    "guidedmodel2.set_params(alpha=optimal_alpha[0]) # notice i did replace something here, Sven (from the class too) figured out the issue, you used an array[float] instead of using a float\n",
    "guidedmodel2.fit(X_train, y_train)\n",
    "y_predicted = guidedmodel2.predict(X_test)\n",
    "\n",
    "print(f'The validation RMSE for this model with '\n",
    "      f'alpha={float(optimal_alpha)} is {rmse(y_test, y_predicted)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 Lasso Path\n",
    "\n",
    "Let's take a look at how RMSE varied across different choices of the regularization hyperparameter ($\\lambda$ in lecture, `alpha` in `sklearn`).  This is often called the Lasso or Regularization Path.  The dashed red line marks the alpha that minimizes RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(alphas, rmses)\n",
    "plt.axvline(x=optimal_alpha, color='red', linestyle='dashed')\n",
    "ax = plt.gca()\n",
    "ax.set_title('Average LASSO RMSE Path')\n",
    "ax.set_xlabel('Regularization Level')\n",
    "ax.set_ylabel('RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2 A simplified approach to Lasso and CV\n",
    "\n",
    "Here we perform another L1-regularized regression but using `LassoCV`.  This is more in line with what we expect from you code-wise.  That being said, you should still understand the concepts from the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the data\n",
    "X_train, y_train = process_data_gm2(train)\n",
    "X_test, y_test = process_data_gm2(test)\n",
    "\n",
    "# Specify the model, alphas, and number of folds for CV\n",
    "alphas = np.arange(0.1, 200.1, .1)\n",
    "guidedmodel2 = lm.LassoCV(alphas=alphas, cv=5)\n",
    "\n",
    "# Fit and predict\n",
    "guidedmodel2.fit(X_train, y_train)\n",
    "y_predicted = guidedmodel2.predict(X_test)\n",
    "\n",
    "print(f'The validation RMSE for this model with '\n",
    "      f'alpha={round(float(guidedmodel2.alpha_), 2)} is '\n",
    "      f'{round(rmse(y_test, y_predicted), 2)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can map out the path that the Lasso algorithm took."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(guidedmodel2.alphas_, np.sqrt(np.apply_along_axis(np.mean, 1, guidedmodel2.mse_path_)))\n",
    "plt.axvline(x=optimal_alpha, color='red', linestyle='dashed')\n",
    "ax = plt.gca()\n",
    "ax.set_title('Average LASSO RMSE Path')\n",
    "ax.set_xlabel('alpha')\n",
    "ax.set_ylabel('RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.3 Lasso Residual Plot\n",
    "\n",
    "Looking at the residual plot for our L1 regularized linear model, it's clear the regularization did not solve the problems we saw in the simple model.  It seems you have your work cut out for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm2_residuals = y_test - y_predicted\n",
    "ax = sns.regplot(x=y_test, y=gm2_residuals)\n",
    "ax.set_xlabel('Sale Price (Test Data)')\n",
    "ax.set_ylabel('Residuals (Actual Price - Predicted Price)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Open-Response\n",
    "\n",
    "The second part of the assignment is purposefully left nearly open-ended. The data in your possession comes from a larger data set. Your goal is to provide a linear model (linear regression, Lasso, Ridge, or other) that accurately predicts the prices of the held-out homes, measured by root mean square error.\n",
    "\n",
    "Please note, that we have intentionally left a part of the testing dataset for ourselves that we are going to check your models for overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading Scheme\n",
    "\n",
    "For the open-response text, we will be checking your approach and whether you followed a proper modeling pipeline and we will also be checking your error on a smaller test set we kept aside for this purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deliverables\n",
    "\n",
    "#### Question 3 <a name=\"q3\"></a>\n",
    "\n",
    "Just as in the guided model above, you should encapsulate as much of your workflow into functions as possible.  Define `process_data_fm` and `final model` in the cell below. In order to calculate your final model's RMSE, we will run the code in the cell after that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(\"ames_train.csv\")\n",
    "test_data = pd.read_csv(\"ames_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my own function to remove outliers, but this isn't much different than the one before\n",
    "\n",
    "def remove_outliers(dataframe, selected_columns, iqr_multiplier):\n",
    "    # get iqr\n",
    "    for column in selected_columns:\n",
    "        if pd.api.types.is_numeric_dtype(dataframe[column]): # we check for numeric data only, makes no sense to check for outliers otherwise\n",
    "            col_dta = np.array(dataframe[column].values) # get column into np.array\n",
    "            iqr = np.percentile(col_dta, 75) - np.percentile(col_dta, 25) # interquartile range (removing outliers based on iqr this time)\n",
    "\n",
    "            l_bound = np.percentile(col_dta, 25) - (iqr_multiplier * iqr)\n",
    "            u_bound = np.percentile(col_dta, 75) + (iqr_multiplier * iqr)\n",
    "\n",
    "            no_outlier_data = dataframe[(col_dta >= l_bound) & (col_dta <= u_bound)]\n",
    "            \n",
    "            dataframe = no_outlier_data\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "remove_outliers(training_data, ['SalePrice'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_missing_data(dataframe): # this will help me check the columns which are not usable\n",
    "    missing_val_count_dict = {}\n",
    "    for column in dataframe.columns:\n",
    "        missing_val_count = dataframe[column].isnull().sum()\n",
    "        missing_val_count_dict[column] = missing_val_count\n",
    "\n",
    "    return missing_val_count_dict\n",
    "\n",
    "print(count_missing_data(training_data))\n",
    "\n",
    "def drop_columns_missing_values(dataframe, bound, include = None): #  gets rid of columns with more than 100 missing values, I do not want to use them\n",
    "    for column in dataframe.columns:\n",
    "        if column in include: # important to not remove columns where missing values are just a \"no\"\n",
    "            missing_val_count = dataframe[column].isnull().sum()\n",
    "            if missing_val_count > bound:\n",
    "                dataframe = dataframe.drop(column, axis = 1)\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "drop_columns_missing_values(training_data, 200, include = ['Lot_Frontage']) # a lot of the values have NaN but this just means \"no\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_wrong_NA(dataframe, exclude=None):\n",
    "    columns_to_replace = [col for col in dataframe.columns if col not in (exclude or [])]\n",
    "\n",
    "    for column in columns_to_replace:\n",
    "        dataframe[column].fillna(\"NA\", inplace=True)\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "replace_wrong_NA(training_data, ['Order', 'PID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this takes a while to actually run, you can do it if needed, but i would not recommend it\n",
    "# it just was useful to show me all the different relations between saleprice and the other variables\n",
    "\n",
    "def plot_price_var_boxplot(dataframe):\n",
    "    for col in dataframe.columns:\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        sns.boxplot(data=dataframe, x=col, y='SalePrice')\n",
    "        plt.title(f'Boxplot for {col}')\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel('SalePrice')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_price_var_boxplot(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Year_Remod_df = pd.DataFrame(training_data.groupby('Year_Remod/Add')['SalePrice'].mean()).reset_index()\n",
    "\n",
    "sns.barplot(data = training_data, x = 'Year_Remod/Add', y = 'SalePrice')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.title('Mean Sale Price Distributed per Year Property was Remodeled')\n",
    "plt.xlabel('Year Remodeled')\n",
    "plt.ylabel('Sale Price (USD)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_MS_Zoning(dataframe): # intuition here is that residential area is more desirable than the rest\n",
    "    replacement_dict = {\n",
    "                        'RL' : 'res_low',\n",
    "                        'RH' : 'res_high',\n",
    "                        'RM' : 'res_medium',\n",
    "                        'RP' : 'res_park',\n",
    "                        'FV' : 'floating_village',\n",
    "                        'I' : 'commercial',\n",
    "                        'C' : 'industrial',\n",
    "                        'A' : 'agriculture'\n",
    "                        }\n",
    "\n",
    "    dataframe['MS_Zoning'] = dataframe['MS_Zoning'].replace(replacement_dict)\n",
    "\n",
    "    cats = ['res_low', 'res_high', 'res_medium', 'res_park', 'floating_village', 'commercial', 'industrial', 'agriculture']\n",
    "\n",
    "    cat_type = CategoricalDtype(categories=cats)\n",
    "\n",
    "    dataframe['MS_Zoning'] = dataframe['MS_Zoning'].astype(cat_type)\n",
    "\n",
    "    dummies = pd.get_dummies(dataframe['MS_Zoning'], prefix='zoning', drop_first=True)\n",
    "\n",
    "    dataframe = pd.concat([dataframe, dummies], axis=1)\n",
    "\n",
    "    dataframe.drop(['MS_Zoning'], axis=1, inplace=True)\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "def group_Overall_Qual(dataframe): # want to group overall finish quality, might not use.\n",
    "    replacement_dict = {\n",
    "                        10 : 'excellent',\n",
    "                        9 : 'excellent',\n",
    "                        8 : 'good',\n",
    "                        7 : 'good',\n",
    "                        6 : 'average',\n",
    "                        5 : 'average',\n",
    "                        4 : 'bad',\n",
    "                        3 : 'bad',\n",
    "                        2 : 'very_bad',\n",
    "                        1 : 'very_bad',\n",
    "                        }\n",
    "\n",
    "    dataframe['Overall_Qual'] = dataframe['Overall_Qual'].replace(replacement_dict)\n",
    "\n",
    "    cats = ['good', 'average', 'bad']\n",
    "\n",
    "    cat_type = CategoricalDtype(categories = cats)\n",
    "\n",
    "    dataframe['Overall_Qual'] = dataframe['Overall_Qual'].astype(cat_type)\n",
    "\n",
    "    dummies = pd.get_dummies(dataframe['Overall_Qual'], prefix='house_qual', drop_first=True)\n",
    "\n",
    "    dataframe = pd.concat([dataframe, dummies], axis=1)\n",
    "\n",
    "    dataframe.drop(['Overall_Qual'], axis=1, inplace=True)\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "def group_Bsmt_Qual(dataframe): # check if basement or not ? maybe this is too specific\n",
    "    replacement_dict = {\n",
    "                        'Ex' : 'excellent',\n",
    "                        'Gd' : 'good',\n",
    "                        'TA' : 'typical',\n",
    "                        'Fa' : 'typical',\n",
    "                        'Po' : 'poor',\n",
    "                        'NA' : 'none'\n",
    "                        }\n",
    "    \n",
    "    dataframe['Bsmt_Qual'] = dataframe['Bsmt_Qual'].replace(replacement_dict)\n",
    "\n",
    "    cats = ['excellent', 'good', 'typical', 'poor', 'none']\n",
    "\n",
    "    cat_type = CategoricalDtype(categories = cats)\n",
    "\n",
    "    dataframe['Bsmt_Qual'] = dataframe['Bsmt_Qual'].astype(cat_type)\n",
    "\n",
    "    dummies = pd.get_dummies(dataframe['Bsmt_Qual'], prefix='basement', drop_first=True)\n",
    "\n",
    "    dataframe = pd.concat([dataframe, dummies], axis=1)\n",
    "\n",
    "    dataframe.drop(['Bsmt_Qual'], axis=1, inplace=True)\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "def group_Exter_Qual(dataframe):\n",
    "    replacement_dict = {\n",
    "                        'Ex' : 'excellent',\n",
    "                        'Gd' : 'good',\n",
    "                        'TA' : 'average',\n",
    "                        'Fa' : 'fair',\n",
    "                        'Po' : 'poor'\n",
    "                        }\n",
    "\n",
    "    dataframe['Exter_Qual'] = dataframe['Exter_Qual'].replace(replacement_dict)\n",
    "\n",
    "    cats = ['excellent', 'good', 'average', 'fair', 'poor']\n",
    "\n",
    "    cat_type = CategoricalDtype(categories = cats)\n",
    "\n",
    "    dataframe['Exter_Qual'] = dataframe['Exter_Qual'].astype(cat_type)\n",
    "\n",
    "    dummies = pd.get_dummies(dataframe['Exter_Qual'], prefix='exter_quality', drop_first=True)\n",
    "\n",
    "    dataframe = pd.concat([dataframe, dummies], axis=1)\n",
    "\n",
    "    dataframe.drop(['Exter_Qual'], axis=1, inplace=True)\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "def group_Functional(dataframe): # house quality, likely that salvage will influence this to some extent ? will need to finetune\n",
    "    replacement_dict = {\n",
    "                        'Typ' : 'good',\n",
    "                        'Min1' : 'good',\n",
    "                        'Min2' : 'good',\n",
    "                        'Mod' : 'good',\n",
    "                        'Maj1' : 'bad',\n",
    "                        'Maj2' : 'bad',\n",
    "                        'Sev' : 'bad',\n",
    "                        'Sal' : 'bad'\n",
    "                        }\n",
    "\n",
    "    dataframe['Functional'] = dataframe['Functional'].replace(replacement_dict)\n",
    "\n",
    "    cats = ['good', 'bad']\n",
    "\n",
    "    cat_type = CategoricalDtype(categories = cats)\n",
    "\n",
    "    dataframe['Functional'] = dataframe['Functional'].astype(cat_type)\n",
    "\n",
    "    dummies = pd.get_dummies(dataframe['Functional'], prefix='functional', drop_first=True)\n",
    "\n",
    "    dataframe = pd.concat([dataframe, dummies], axis=1)\n",
    "\n",
    "    dataframe.drop(['Functional'], axis=1, inplace=True)\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "def group_Garage_Cars(dataframe): # having a garage should increase the value of the property\n",
    "    replacement_dict = {\n",
    "                        1 : 'small',\n",
    "                        2 : 'small',\n",
    "                        3 : 'average',\n",
    "                        4 : 'big',\n",
    "                        5 : 'big',\n",
    "                        'NA' : 'none'\n",
    "                        }\n",
    "\n",
    "    dataframe['Garage_Cars'] = dataframe['Garage_Cars'].replace(replacement_dict)\n",
    "\n",
    "    cats = ['good', 'average', 'bad', 'poor']\n",
    "\n",
    "    cat_type = CategoricalDtype(categories = cats)\n",
    "\n",
    "    dataframe['Garage_Cars'] = dataframe['Garage_Cars'].astype(cat_type)\n",
    "\n",
    "    dummies = pd.get_dummies(dataframe['Garage_Cars'], prefix='garage_size', drop_first=True)\n",
    "\n",
    "    dataframe = pd.concat([dataframe, dummies], axis=1)\n",
    "\n",
    "    dataframe.drop(['Garage_Cars'], axis=1, inplace=True)\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "def group_Pool_QC(dataframe) : # maybe having a pool could increase value of house ?\n",
    "    replacement_dict = {\n",
    "                        'Ex' : 'yes',\n",
    "                        'Gd' : 'yes',\n",
    "                        'TA' : 'yes',\n",
    "                        'NA' : 'no'\n",
    "                        }\n",
    "\n",
    "    dataframe['Pool_QC'] = dataframe['Pool_QC'].replace(replacement_dict)\n",
    "\n",
    "    cats = ['yes', 'no']\n",
    "\n",
    "    cat_type = CategoricalDtype(categories = cats)\n",
    "\n",
    "    dataframe['Pool_QC'] = dataframe['Pool_QC'].astype(cat_type)\n",
    "\n",
    "    dummies = pd.get_dummies(dataframe['Pool_QC'], prefix='pool', drop_first=True)\n",
    "\n",
    "    dataframe = pd.concat([dataframe, dummies], axis=1)\n",
    "\n",
    "    dataframe.drop(['Pool_QC'], axis=1, inplace=True)\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "def group_Central_Air(dataframe):\n",
    "    replacement_dict = {\n",
    "                        'Y' : 'yes',\n",
    "                        'N' : 'no'\n",
    "                        }\n",
    "    \n",
    "    dataframe['Central_Air'] = dataframe['Central_Air'].replace(replacement_dict)\n",
    "\n",
    "    cats = ['yes', 'no']\n",
    "\n",
    "    cat_type = CategoricalDtype(categories = cats)\n",
    "\n",
    "    dataframe['Central_Air'] = dataframe['Central_Air'].astype(cat_type)\n",
    "\n",
    "    dummies = pd.get_dummies(dataframe['Central_Air'], prefix='central_air', drop_first=True)\n",
    "\n",
    "    dataframe = pd.concat([dataframe, dummies], axis=1)\n",
    "\n",
    "    dataframe.drop(['Central_Air'], axis=1, inplace=True)\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "def group_Full_Bath(dataframe):\n",
    "    replacement_dict = {\n",
    "                        0 : 'zero',\n",
    "                        1 : 'one',\n",
    "                        2 : 'two',\n",
    "                        3 : 'three',\n",
    "                        4 : 'four'\n",
    "                        }\n",
    "    \n",
    "    dataframe['Full_Bath'] = dataframe['Full_Bath'].replace(replacement_dict)\n",
    "\n",
    "    cats = ['zero', 'one', 'two', 'three', 'four']\n",
    "\n",
    "    cat_type = CategoricalDtype(categories = cats)\n",
    "\n",
    "    dataframe['Full_Bath'] = dataframe['Full_Bath'].astype(cat_type)\n",
    "\n",
    "    dummies = pd.get_dummies(dataframe['Full_Bath'], prefix='bathrooms_full', drop_first=True)\n",
    "\n",
    "    dataframe = pd.concat([dataframe, dummies], axis=1)\n",
    "\n",
    "    dataframe.drop(['Full_Bath'], axis=1, inplace=True)\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "def group_Fireplace_Qu(dataframe):\n",
    "    replacement_dict = {\n",
    "                        'Ex' : 'excellent',\n",
    "                        'Gd' : 'good',\n",
    "                        'TA' : 'good',\n",
    "                        'Fa' : 'good',\n",
    "                        'Po' : 'good',\n",
    "                        'NA' : 'none'\n",
    "                        }\n",
    "\n",
    "    dataframe['Fireplace_Qu'] = dataframe['Fireplace_Qu'].replace(replacement_dict)\n",
    "\n",
    "    cats = ['excellent', 'good', 'none']\n",
    "\n",
    "    cat_type = CategoricalDtype(categories = cats)\n",
    "\n",
    "    dataframe['Fireplace_Qu'] = dataframe['Fireplace_Qu'].astype(cat_type)\n",
    "\n",
    "    dummies = pd.get_dummies(dataframe['Fireplace_Qu'], prefix='fireplace_quality', drop_first=True)\n",
    "\n",
    "    dataframe = pd.concat([dataframe, dummies], axis=1)\n",
    "\n",
    "    dataframe.drop(['Fireplace_Qu'], axis=1, inplace=True)\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "def group_TotRms_AbvGd(dataframe): # not use this one, maybe later\n",
    "    replacement_dict = {\n",
    "                        1 : 'not_many',\n",
    "                        2 : 'not_many',\n",
    "                        3 : 'not_many',\n",
    "                        4 : 'not_many',\n",
    "                        5 : 'average',\n",
    "                        6 : 'average',\n",
    "                        7 : 'average',\n",
    "                        8 : 'lots',\n",
    "                        9 : 'lots',\n",
    "                        10 : 'lots',\n",
    "                        11 : 'lots',\n",
    "                        12 : 'lots',\n",
    "                        }\n",
    "\n",
    "    dataframe['TotRms_AbvGd'] = dataframe['TotRms_AbvGd'].replace(replacement_dict)\n",
    "\n",
    "    cats = ['not_many', 'average', 'lots']\n",
    "\n",
    "    cat_type = CategoricalDtype(categories = cats)\n",
    "\n",
    "    dataframe['TotRms_AbvGd'] = dataframe['TotRms_AbvGd'].astype(cat_type)\n",
    "\n",
    "    dummies = pd.get_dummies(dataframe['TotRms_AbvGd'], prefix='rooms_abvg', drop_first=True)\n",
    "\n",
    "    dataframe = pd.concat([dataframe, dummies], axis=1)\n",
    "\n",
    "    dataframe.drop(['TotRms_AbvGd'], axis=1, inplace=True)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_remodel_year(dataframe):\n",
    "    dataframe['remodel_year'] = pd.cut(dataframe['Year_Remod/Add'], \n",
    "                            bins=[1950, 1968, 1983, 1992, 2005, 2010], \n",
    "                            labels=['1950-1968', '1969-1983', '1983-1992', '1992-2005', '2006-2010'], \n",
    "                            right=False)\n",
    "    \n",
    "    dummies = pd.get_dummies(dataframe['remodel_year'], prefix='remodel_year', drop_first=True)\n",
    "\n",
    "    dataframe = pd.concat([dataframe, dummies], axis=1)\n",
    "\n",
    "    dataframe.drop(['remodel_year'], axis=1, inplace=True)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_columns(data):\n",
    "    standardized_data = (data - np.mean(data)) / np.std(data) # z score\n",
    "\n",
    "    return standardized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a ground breaking new feature -> lot size / living area\n",
    "\n",
    "def garden_house_ratio(dataframe):\n",
    "    dataframe['g_h_ratio'] = dataframe['Lot_Area'] / dataframe['Gr_Liv_Area']\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_Neighborhood(dataframe): # will revise the grouping of this variable later, working prototype\n",
    "    replacement_dict = {\n",
    "                        'StoneBr' : 'rich',\n",
    "                        'NridgHt' : 'rich',\n",
    "                        'NoRidge' : 'rich',\n",
    "                        'GrnHill' : 'rich',\n",
    "                        'Veenker' : 'moderate',\n",
    "                        'Timber'  : 'moderate',\n",
    "                        'Somerst' : 'moderate',\n",
    "                        'Greens'  : 'moderate',\n",
    "                        'CollgCr' : 'moderate',\n",
    "                        'Crawfor' : 'moderate',\n",
    "                        'Blmngtn' : 'moderate',\n",
    "                        'ClearCr' : 'moderate',\n",
    "                        'NWAmes'  : 'moderate',\n",
    "                        'Gilbert' : 'moderate',\n",
    "                        'SawyerW' : 'moderate',\n",
    "                        'Mitchel' : 'moderate',\n",
    "                        'NPkVill' : 'moderate',\n",
    "                        'NAmes'   : 'poor',\n",
    "                        'Sawyer'  : 'poor',\n",
    "                        'SWISU'   : 'poor',\n",
    "                        'Edwards' : 'poor',\n",
    "                        'Blueste' : 'poor',\n",
    "                        'BrkSide' : 'poor',\n",
    "                        'OldTown' : 'poor',\n",
    "                        'BrDale'  : 'poor',\n",
    "                        'IDOTRR'  : 'poor',\n",
    "                        'MeadowV' : 'poor'\n",
    "                        }\n",
    "\n",
    "    dataframe['Neighborhood'] = dataframe['Neighborhood'].replace(replacement_dict)\n",
    "\n",
    "    cats = ['rich', 'moderate', 'poor']\n",
    "\n",
    "    cat_type = CategoricalDtype(categories = cats)\n",
    "\n",
    "    dataframe['Neighborhood'] = dataframe['Neighborhood'].astype(cat_type)\n",
    "\n",
    "    dummies = pd.get_dummies(dataframe['Neighborhood'], prefix='neighborhood', drop_first=True)\n",
    "\n",
    "    dataframe = pd.concat([dataframe, dummies], axis=1)\n",
    "\n",
    "    dataframe.drop(['Neighborhood'], axis=1, inplace=True)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def richest_neighborhoods(dataframe):\n",
    "    rich_countries = dataframe.groupby('Neighborhood')['SalePrice'].median().sort_values(ascending = False)\n",
    "    return rich_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_duplicates(dataframe): # no duplicates, good\n",
    "    dupes = dataframe[dataframe.duplicated()]\n",
    "\n",
    "    return dupes\n",
    "\n",
    "check_duplicates(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummies(dataframe): # creates dummies for each column\n",
    "    dataframe = group_Bsmt_Qual(dataframe)\n",
    "    dataframe = group_Central_Air(dataframe)\n",
    "    dataframe = group_Exter_Qual(dataframe)\n",
    "    dataframe = group_Fireplace_Qu(dataframe)\n",
    "    dataframe = group_Full_Bath(dataframe)\n",
    "    dataframe = group_Functional(dataframe)\n",
    "    dataframe = group_Garage_Cars(dataframe)\n",
    "    dataframe = group_MS_Zoning(dataframe)\n",
    "    dataframe = group_Neighborhood(dataframe)\n",
    "    dataframe = group_Overall_Qual(dataframe)\n",
    "    dataframe = group_Pool_QC(dataframe)\n",
    "    dataframe = group_remodel_year(dataframe)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(actual, predicted):\n",
    "    rmse = np.sqrt(np.mean((np.array(actual) - np.array(predicted)) ** 2))\n",
    "\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apologies for not using the whole pipeline thing, this just works\n",
    "\n",
    "def process_data_fm(data):\n",
    "    # Clean Data\n",
    "    data = remove_outliers(data, ['SalePrice'], 3)\n",
    "    data = drop_columns_missing_values(data, 200, ['Lot_Frontage'])\n",
    "    data = replace_wrong_NA(data, ['Order', 'PID'])\n",
    "\n",
    "    # Transform Data\n",
    "    data = garden_house_ratio(data) # create new ground breaking feature\n",
    "    data = create_dummies(data) # create all the dummies for the model\n",
    "\n",
    "    # More?\n",
    "    y = data['SalePrice']\n",
    "    X = data.drop(['SalePrice'], axis = 1)\n",
    "    X = X.loc[:, 'g_h_ratio':]\n",
    "    standardize_columns(X['g_h_ratio'])\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(\"ames_train.csv\")\n",
    "test_data = pd.read_csv(\"ames_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the data\n",
    "X_train, y_train = process_data_fm(training_data)\n",
    "X_test, y_test = process_data_fm(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the same code written above in item 2. \n",
    "# i use lasso, ridge does not converge with my model \n",
    "\n",
    "# Process the data\n",
    "X_train, y_train = process_data_fm(training_data)\n",
    "X_test, y_test = process_data_fm(test_data)\n",
    "\n",
    "# Specify the model, alphas, and number of folds for CV\n",
    "alphas = np.arange(0.1, 200.1, .1)\n",
    "lassoModel = lm.LassoCV(alphas = alphas, cv = 5)\n",
    "\n",
    "# Fit and predict\n",
    "lassoModel.fit(X_train, y_train)\n",
    "y_predicted = lassoModel.predict(X_test)\n",
    "\n",
    "print(f'The validation RMSE for this model with '\n",
    "      f'alpha={round(float(guidedmodel2.alpha_), 2)} is '\n",
    "      f'{round(rmse(y_test, y_predicted), 2)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The residual plot shows a slight upwards trend, and a small increase in variance as the sale price increases, which is to be expected given the fact that we simply have less data sets for more expensive properties. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_residuals = y_test - y_predicted\n",
    "ax = sns.regplot(x=y_test, y=fm_residuals)\n",
    "ax.set_xlabel('Sale Price (Test Data)')\n",
    "ax.set_ylabel('Residuals (Actual Price - Predicted Price)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.arange(0.1, 200.1, .1)\n",
    "final_model = lm.LassoCV(alphas=alphas, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I find alpha = 59.7\n",
    "RMSE = 31646.85\n",
    "\n",
    "overall a decent improvement from the \"showcase\" model in part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('ames_train.csv')\n",
    "X_train, y_train = process_data_fm(training_data)\n",
    "final_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##keep these for now. we will use this to check your models\n",
    "\n",
    "#training_data = pd.read_csv('ames_train.csv')\n",
    "#public_test_data = pd.read_csv('ames_test.csv')\n",
    "#public_test_data = pd.read_csv('public_test_set.csv')\n",
    "#private_test_data = pd.read_csv('private_test_set.csv')\n",
    "\n",
    "#X_train, y_train = process_data_fm(training_data)\n",
    "#X_public, y_public = process_data_fm(public_test_data)\n",
    "#X_private, y_private = process_data_fm(private_test_data)\n",
    "\n",
    "#final_model.fit(X_train, y_train)\n",
    "#y_predicted_train = final_model.predict(X_train)\n",
    "#y_predicted_public = final_model.predict(X_public)\n",
    "#y_predicted_private = final_model.predict(X_private)\n",
    "\n",
    "#training_score = rmse(y_predicted_train, y_train)\n",
    "#public_score = rmse(y_predicted_public, y_public)\n",
    "#private_score = rmse(y_predicted_private, y_private)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. The aftermath\n",
    "\n",
    "The following questions are supposed to be answered after you have completed your model submission and they are supposed to be used as reflection of the whole modeling process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4<a name=\"q4\"></a>\n",
    "\n",
    "In addition, please submit one visualization from your EDA with 2-5 sentences describing why you thought the plot was interesting and what decisions it led to in your model specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Year_Remod_df = pd.DataFrame(training_data.groupby('Year_Remod/Add')['SalePrice'].mean()).reset_index()\n",
    "\n",
    "sns.barplot(data = training_data, x = 'Year_Remod/Add', y = 'SalePrice')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.title('Mean Sale Price Distributed per Year Property was Remodeled')\n",
    "plt.xlabel('Year Remodeled')\n",
    "plt.ylabel('Sale Price (USD)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER**\n",
    "\n",
    "As you can see on the plot I provided above, mean sale price is correlated to how recent a house was remodeled (or built if no remodel). We can see quite a strong increase in sale price as the properties get more recent. This should definitely not be ignored.\n",
    "\n",
    "What this led me to do is incorportate it in my model, to do so I have just separated the houses in 5 categories; \n",
    "\n",
    "-> 1950 - 1968\n",
    "\n",
    "-> 1969 - 1983\n",
    "\n",
    "-> 1984 - 1992\n",
    "\n",
    "-> 1993 - 2005\n",
    "\n",
    "-> 2005 - 2010\n",
    "\n",
    "this may not be perfect and very precise but I hope to have captured the effect of this variable on sale price!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 5 <a name=\"q5\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name a feature that isn't listed in this dataset but may be useful for predicting sales values. What insights could this feature provide? How might it increase or decrease a home’s sales value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER**\n",
    "\n",
    "I would have to say some indicator about the quality of the nearest schools would help a lot in determining house prices. After all, it is normal to expect that houses which are very close to good schools would typically sell for more than houses either far away or close to mediocre schools. Now this would only affect families valuation of houses, but we saw in this dataset that single family houses were the most common entry in the dataset, so this would be a good variable to have, in my opinion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 6 <a name=\"q6\"></a>\n",
    "\n",
    "When evaluating your model, we used root mean squared error. Of course, in the context of our machine learning models that is great. However, In the context of estimating the value of houses, what does error mean for an individual homeowner? How does it affect them in terms of property taxes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of the Cook County Assessor’s Office, Chief Data Officer Rob Ross states that fair property tax rates are contingent on whether property values are assessed accurately - that they’re valued at what they’re worth, relative to properties with similar characteristics. This implies that having a more accurate model results in fairer assessments. The goal of the property assessment process for the CCAO, then, is to be as accurate as possible.\n",
    "\n",
    "When the use of algorithms and statistical modeling has real-world consequences, we often refer to the idea of fairness as a measurement of how socially responsible our work is. But fairness is incredibly multifaceted: Is a fair model one that minimizes loss - one that generates accurate results? Is it one that utilizes \"unbiased\" data? Or is fairness a broader goal that takes historical contexts into account?\n",
    "\n",
    "These approaches to fairness are not mutually exclusive. If we look beyond error functions and technical measures of accuracy, we'd not only consider individual cases of fairness, but also what fairness - and justice - means to marginalized communities on a broader scale. We'd ask: What does it mean when homes in predominantly Black and Hispanic communities in Cook County are consistently overvalued, resulting in proportionally higher property taxes? When the white neighborhoods in Cook County are consistently undervalued, resulting in proportionally lower property taxes?\n",
    "\n",
    "Having \"accurate\" predictions doesn't necessarily address larger historical trends and inequities, and fairness in property assessments in taxes works beyond the CCAO's valuation model. Disassociating accurate predictions from a fair system is vital to approaching justice at multiple levels. Take Evanston, IL - a suburb in Cook County - as an example of housing equity beyond just improving a property valuation model: Their City Council members [recently approved reparations for African American residents](https://www.usnews.com/news/health-news/articles/2021-03-23/chicago-suburb-approves-government-reparations-for-black-residents)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final question to this (hopefully eye opening clinic), describe (in your own words) how you would define fairness in property assessments and taxes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER**\n",
    "\n",
    "For individual homeowners, model error can either lead us to overestimate or underestimate the value of houses. Of course, if our model consistantly overvalues cheap houses, then those people will end up paying higher property taxes, and vice versa. It creates a divide. \n",
    "\n",
    "In my opinion, while historical context does have a part in determining whether our model is fair or not, if we are to take house prices in this current day into consideration for our model, then the most fair model should be one which is unbiased. Yes, different parties may not be pleased with the market, but it is more important to be unbiased than to overinflate some houses' price and vice-versa. I would not include any factor which would influence house prices based on what community the owner identifies with, but rather only look at people's financial situation individually.\n",
    "\n",
    "Consistent overvaluation of black and hispanic houses perpetrates historical disparities between those communities and white communities. Furthermore, it also imposes an important tax burden on people who are unlikely to be able to afford their houses in the first place. \n",
    "\n",
    "I believe fairness starts with an accurate valuation of house prices for all neighborhoods. What is also important to take into account is the financial situation of the people in different neighborhoods. This would avoid taking ethnicity into account and creating further bias in valuation, but would instead make sure houses are valued independently of their owner. This is a fair treatment in terms of valuation, and therefore in terms of taxes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
